{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d1b67df-1d86-4054-b5f6-3b2b6e28e35a",
   "metadata": {},
   "source": [
    "# Exploring Classics with RAG: Analyzing The Master and Margarita"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed496e13-da80-4da8-9f4e-a828718304e0",
   "metadata": {},
   "source": [
    "This is my first experience working with large language models (LLMs) and Retrieval-Augmented Generation (RAG) techniques. I am excited to explore how these technologies can be applied to literary analysis, starting with the iconic novel The Master and Margarita by Mikhail Bulgakov. Through this project, I aim to gain hands-on experience with LLMs and RAG, and to demonstrate their potential in analyzing and interpreting classical literature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd04c47f-abfa-4ca8-aaab-f0b2c735b3ae",
   "metadata": {},
   "source": [
    "In this code, I begin by setting up the environment for my project, including importing necessary libraries and configuring API keys. The script imports modules from LangChain to handle document loading, text splitting, and vector storage. It also sets the OpenAI API key for using OpenAI’s services. The load_documents function is used to load markdown files from a specified directory, which will then be processed for analysis. This setup prepares the data for further indexing and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfbb2e50-9e74-45ac-8b52-354e45397ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import Document\n",
    "import openai \n",
    "import shutil\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'key'\n",
    "\n",
    "DATA_PATH = 'data'\n",
    "CHROMA_PATH = 'chroma'\n",
    "\n",
    "def load_documents():\n",
    "    loader = DirectoryLoader(DATA_PATH, glob='*.md')\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "documents = load_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884b5517-cb59-4710-a713-56760d65183f",
   "metadata": {},
   "source": [
    "In the code below, I utilize the RecursiveCharacterTextSplitter from LangChain to divide the loaded documents into manageable chunks. The text splitter is configured to create chunks of 1000 characters with a 300-character overlap, ensuring that relevant context is preserved between chunks. This process enhances the ability to analyze and retrieve specific parts of the text efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1df950-93be-4cc5-83ef-76668e2671d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 documents into 1417 chunks.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=300,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f'Split {len(documents)} documents into {len(chunks)} chunks.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd02eb43-c177-4831-b4c5-554a1ef1aa6c",
   "metadata": {},
   "source": [
    "Let's take a look at one of the chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc557781-8d0c-4d43-b7f0-1cd709834e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Sure nobody knows,' the same trashy voice came from the study. The\n",
      "binomial theorem, you might think! He's going to die in nine months,\n",
      "next February, of liver cancer, in the clinic of the First Moscow State\n",
      "University, in ward number four.'\n",
      "\n",
      "The barman's face turned yellow.\n",
      "\n",
      "'Nine months ...' Woland calculated pensively. 'Two hundred and\n",
      "forty-nine thousand ... rounding it off that comes to twenty-seven\n",
      "thousand a month ... Not a lot, but enough for a modest life ... Plus\n",
      "those gold pieces ...'\n",
      "\n",
      "'He won't get to realize the gold pieces,' the same voice mixed in,\n",
      "turning the barman's heart to ice. 'On Andrei Fokich's demise, the house\n",
      "will immediately be torn down, and the gold will be sent to the State\n",
      "Bank.'\n",
      "{'source': 'data\\\\Master and Margarita Bulgakov.md', 'start_index': 497052}\n"
     ]
    }
   ],
   "source": [
    "document = chunks[713]\n",
    "print(document.page_content)\n",
    "print(document.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e13f405-479e-4e81-ac70-4138f82ceb1a",
   "metadata": {},
   "source": [
    "In the next code, I create a new vector database from the processed document chunks using the Chroma class from LangChain. This involves initializing the database with the document chunks and using OpenAI embeddings to convert the text into vector representations. The persist_directory parameter specifies where to store the database, enabling efficient storage and retrieval of the text data. This setup allows for scalable and fast retrieval of information for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b82c96-4266-416a-bc51-0dea30277c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1417 chunks to chroma3.\n"
     ]
    }
   ],
   "source": [
    "#Create a new DB from the documents.\n",
    "db = Chroma.from_documents(\n",
    "    chunks, OpenAIEmbeddings(), persist_directory=CHROMA_PATH\n",
    ")\n",
    "print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd75f6e-bc4c-45d4-b2ed-37711b01ef28",
   "metadata": {},
   "source": [
    "To better understand how text embeddings work and how semantic distances are calculated, I start with the word \"apple.\" By examining how this term is represented in vector space, I can gain insight into the underlying mechanics of the embedding process. Specifically, I’ll compare the semantic distance between \"apple\" and two other words, \"orange\" and \"iphone,\" to see how closely related or distinct these terms are based on their embeddings.\n",
    "\n",
    "This initial test with the word \"apple\" helps illustrate how the embedding model differentiates between concepts and quantifies their semantic similarity. It serves as a foundation for more detailed analysis, allowing me to grasp the nuances of text representation and how these embeddings can be applied to a larger and more complex dataset, such as the novel The Master and Margarita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32695665-fbc5-41ac-b6eb-3b3371787c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "embedding_function = OpenAIEmbeddings()\n",
    "vector = embedding_function.embed_query('apple')\n",
    "print(len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475381c6-2b62-45b1-bbf1-37ea597f72f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.1354698831743597}\n",
      "{'score': 0.09712998362468106}\n"
     ]
    }
   ],
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "evaluator = load_evaluator('pairwise_embedding_distance')\n",
    "#Run an avaluation\n",
    "x = evaluator.evaluate_string_pairs(prediction='apple', prediction_b='orange')\n",
    "print(x)\n",
    "x1 = evaluator.evaluate_string_pairs(prediction='apple', prediction_b='iphone')\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aff749c-f25d-4287-b033-da9b7fc2476a",
   "metadata": {},
   "source": [
    "These scores indicate that, according to the embedding model, \"apple\" is somewhat closer in semantic space to \"iphone\" than to \"orange.\" This suggests that the model perceives \"apple\" and \"iphone\" as more related, likely due to their shared context as consumer electronics, whereas \"orange\" is semantically more distant, being a different category altogether. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d52f5-d52a-4264-b8ec-f5baf3dd849b",
   "metadata": {},
   "source": [
    "But let's get back to our novel!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f796c7a3-058c-4497-a6c3-0207033e6900",
   "metadata": {},
   "source": [
    "In this code, I set up the vector database using Chroma and the OpenAIEmbeddings for converting text into vectors. The database is configured to use the directory where the vector data is stored. This setup allows me to efficiently manage and search the text data based on its embeddings, making it easier to perform further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b99c0b4-7af3-47c7-8ad7-0fa6f5dfa986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DB.\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86c61c1-be63-4bc2-9d64-309a09027293",
   "metadata": {},
   "source": [
    "I prefer to strart from easy questions like this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d968ee34-9d74-4c21-b3cd-4a5ddeaa48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = 'Who are the main characters of the book The Master and Margarita?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b80783-285c-4f64-809f-aeb244beecfe",
   "metadata": {},
   "source": [
    "In the code below the similarity_search_with_relevance_scores method will find and rank the top 3 most relevant document chunks based on how closely they match the query. This helps in retrieving specific information related to the main characters of the novel, allowing for focused and relevant insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "812b8711-87be-42b8-a8c3-63b1b54ce3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content=\"At his death, Bulgakov left [The Master and Margarita]{.italic} in a\\nslightly unfinished state. It contains, for instance, certain\\ninconsistencies --- two versions of the 'departure' of the master and\\nMargarita, two versions of Yeshua's entry into Yershalaim, two names for\\nYeshua's native town. His final revisions, undertaken in October of\\n1939, broke off near the start of Book Two. Later he dictated some\\nadditions to his wife, Elena Sergeevna, notably the opening paragraph of\\nChapter 32 ('Gods, my gods! How sad the evening earth!'). Shortly after\\nhis death in 1940, Elena Sergeevna made a new typescript of the novel.\\nIn 1963, she prepared another typescript for publication, which differs\\nslightly from her 1940 text. This 1963 text was published by\\n[Moskva]{.italic} in November 1966 and January 1967. However, the\\neditors of the magazine made cuts in it amounting to some sixty typed\\npages. These cut portions immediately appeared in [samizdat]{.italic}\", metadata={'source': 'data\\\\Master and Margarita Bulgakov.md', 'start_index': 40234}),\n",
       "  0.8085636614137585),\n",
       " (Document(page_content='[Penguin Books Ltd, Registered Offices: 80 Strand, London WC2R oRL,\\nEngland]{.calibre15}\\n\\n[First published as ]{.calibre15}[[Master i\\nMargarita]{.italic}]{.calibre15}[ in serial form in\\n]{.calibre15}[[Moskva,]{.italic}]{.calibre15}[ 1966-7 ]{.calibre15}\\\\\\n[This translation published in Penguin Books 1997]{.calibre15}\\n\\n\\\\\\n\\\\\\n\\\\\\n\\n[Text copyright © Mikhail Bulgakov, 1966, 1967]{.calibre15}\\n\\n[Translation, Further Reading and Notes copyright © Richard Pevear and\\n]{.calibre15}\\\\\\n[Larissa Volokhonsky, 1997 ]{.calibre15}\\\\\\n[Introduction copyright © Richard Pevear, 1997 ]{.calibre15}\\\\\\n[All rights reserved]{.calibre15}\\n\\n[eISBN : 978-1-440-67408-2]{.calibre15}\\n\\n[Set in 10/12pt Monotype Garamond ]{.calibre15}\\\\', metadata={'source': 'data\\\\Master and Margarita Bulgakov.md', 'start_index': 9524}),\n",
       "  0.7986563492482723),\n",
       " (Document(page_content='[Chapter 29: The Fate of the Master and Margarita is Decided]{.italic}\\n\\n[]{.calibre11}[]{#The_Master_and_Margarita_split_045.html#filepos1170033\\n.calibre11}\\n\\n[[1]{.calibre8\\nstyle=\"text-decoration:underline\"}]{.calibre7}{.calibre6}\\n[Resting his sharp chin on his fist]{.italic} ... [Woland stand\\nfixedly:]{.italic} Woland seems almost consciously to adopt the pose of\\nRodin\\'s famous sculpture known as the [Thinker,]{.italic} actually the\\ncentral figure over his [Gates of Hell.]{.italic}\\n\\n[]{.calibre11}[]{#The_Master_and_Margarita_split_045.html#filepos1170386\\n.calibre11}\\n\\n[[2]{.calibre8\\nstyle=\"text-decoration:underline\"}]{.calibre7}{.calibre6}\\n[to Timiriazev]{.italic}: That is, to the statue of the botanist and\\nfounder of the Russian school of plant physiology, Kliment Arkadyevich\\nTimiriazev (1843 - 1910), on Tverskoy Boulevard near the Nikitsky Gates.\\n\\n[Chapter 30: It\\'s Time! It\\'s Time!]{.italic}\\n\\n[]{.calibre11}[]{#The_Master_and_Margarita_split_045.html#filepos1170802\\n.calibre11}', metadata={'source': 'data\\\\Master and Margarita Bulgakov.md', 'start_index': 982775}),\n",
       "  0.7978212830562611)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search the DB.\n",
    "results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ce709-f693-43df-83a3-b4189330542a",
   "metadata": {},
   "source": [
    "The output contains the top 3 results from the database search for the query \"Who are the main characters of the book The Master and Margarita?\". All the retrieved results have very similar scores, ranging from 0.798 to 0.809. This indicates that the system retrieved documents with nearly the same relevance score. \n",
    "\n",
    "Despite having queried for the main characters, only the third document provides partial context that includes \"the Master\" and \"Margarita\" in the story. The other documents, though relevant to the book's publication history, do not provide the information needed to answer the query effectively. The scores of the documents are close in range, but the relevance varies greatly. While Document 1 has the highest score, it does not contribute much to answering the query directly.\n",
    "\n",
    "I suppose for improvement, that metadata such as publication details, ISBNs, and copyright information should be ignored. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb064ba-6333-46f4-86da-773f8226079d",
   "metadata": {},
   "source": [
    "The next step ensures that only results with a high enough relevance score are considered, helping to maintain the quality of the retrieved information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b303cdcd-70bf-44bd-a9e4-66832e149e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results) == 0 or results[0][1] < 0.7:\n",
    "    print(f'Unable to find matching results.')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e5b-577e-48b1-8e97-c49612f25afa",
   "metadata": {},
   "source": [
    "In the next code, I create a simple but powerful tool called a prompt template. A prompt is a way to instruct the AI on how to answer a question using specific information.\n",
    "\n",
    "Here's what this prompt template does:\n",
    "\n",
    "Provides Context: It takes the relevant information from the database and includes it in the context section.\n",
    "Asks a Question: It then inserts the actual question that needs to be answered based on that context.\n",
    "\n",
    "This setup helps the AI focus only on the provided context when answering, making sure the response is accurate and relevant. It’s a straightforward way to get precise answers from the AI, tailored to the information you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3abb50f-e5d4-4114-ab7a-461451a41a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44162d5-7d84-438f-84ec-f442dceed01d",
   "metadata": {},
   "source": [
    "In this code, I combine the context and question into a formatted prompt and send it to the AI model to generate a response. Here's a breakdown of what happens:\n",
    "- Create Context: The 'context_text' is built by joining the relevant text chunks (from the search results) with separators like \"\\n\\n---\\n\\n\" to maintain structure.\n",
    "\n",
    "- Format the Prompt: The prompt template is filled with the context_text and the query_text (the question being asked) using 'ChatPromptTemplate'. This creates the final prompt, which is what the AI will use to generate its response.\n",
    "\n",
    "- Invoke the Model: The 'ChatOpenAI' model is called with the formatted prompt, and it returns the answer based on the context provided.\n",
    "\n",
    "- Format the Response: Finally, the code formats the response, displaying both the AI's answer and the sources from which the information was pulled. This gives clear output showing the AI's reasoning and where the data came from.\n",
    "\n",
    "This entire process ensures that the AI answers the question with accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e90d7d8-d519-4fa0-a93c-11bd41621f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "At his death, Bulgakov left [The Master and Margarita]{.italic} in a\n",
      "slightly unfinished state. It contains, for instance, certain\n",
      "inconsistencies --- two versions of the 'departure' of the master and\n",
      "Margarita, two versions of Yeshua's entry into Yershalaim, two names for\n",
      "Yeshua's native town. His final revisions, undertaken in October of\n",
      "1939, broke off near the start of Book Two. Later he dictated some\n",
      "additions to his wife, Elena Sergeevna, notably the opening paragraph of\n",
      "Chapter 32 ('Gods, my gods! How sad the evening earth!'). Shortly after\n",
      "his death in 1940, Elena Sergeevna made a new typescript of the novel.\n",
      "In 1963, she prepared another typescript for publication, which differs\n",
      "slightly from her 1940 text. This 1963 text was published by\n",
      "[Moskva]{.italic} in November 1966 and January 1967. However, the\n",
      "editors of the magazine made cuts in it amounting to some sixty typed\n",
      "pages. These cut portions immediately appeared in [samizdat]{.italic}\n",
      "\n",
      "---\n",
      "\n",
      "[Penguin Books Ltd, Registered Offices: 80 Strand, London WC2R oRL,\n",
      "England]{.calibre15}\n",
      "\n",
      "[First published as ]{.calibre15}[[Master i\n",
      "Margarita]{.italic}]{.calibre15}[ in serial form in\n",
      "]{.calibre15}[[Moskva,]{.italic}]{.calibre15}[ 1966-7 ]{.calibre15}\\\n",
      "[This translation published in Penguin Books 1997]{.calibre15}\n",
      "\n",
      "\\\n",
      "\\\n",
      "\\\n",
      "\n",
      "[Text copyright © Mikhail Bulgakov, 1966, 1967]{.calibre15}\n",
      "\n",
      "[Translation, Further Reading and Notes copyright © Richard Pevear and\n",
      "]{.calibre15}\\\n",
      "[Larissa Volokhonsky, 1997 ]{.calibre15}\\\n",
      "[Introduction copyright © Richard Pevear, 1997 ]{.calibre15}\\\n",
      "[All rights reserved]{.calibre15}\n",
      "\n",
      "[eISBN : 978-1-440-67408-2]{.calibre15}\n",
      "\n",
      "[Set in 10/12pt Monotype Garamond ]{.calibre15}\\\n",
      "\n",
      "---\n",
      "\n",
      "[Chapter 29: The Fate of the Master and Margarita is Decided]{.italic}\n",
      "\n",
      "[]{.calibre11}[]{#The_Master_and_Margarita_split_045.html#filepos1170033\n",
      ".calibre11}\n",
      "\n",
      "[[1]{.calibre8\n",
      "style=\"text-decoration:underline\"}]{.calibre7}{.calibre6}\n",
      "[Resting his sharp chin on his fist]{.italic} ... [Woland stand\n",
      "fixedly:]{.italic} Woland seems almost consciously to adopt the pose of\n",
      "Rodin's famous sculpture known as the [Thinker,]{.italic} actually the\n",
      "central figure over his [Gates of Hell.]{.italic}\n",
      "\n",
      "[]{.calibre11}[]{#The_Master_and_Margarita_split_045.html#filepos1170386\n",
      ".calibre11}\n",
      "\n",
      "[[2]{.calibre8\n",
      "style=\"text-decoration:underline\"}]{.calibre7}{.calibre6}\n",
      "[to Timiriazev]{.italic}: That is, to the statue of the botanist and\n",
      "founder of the Russian school of plant physiology, Kliment Arkadyevich\n",
      "Timiriazev (1843 - 1910), on Tverskoy Boulevard near the Nikitsky Gates.\n",
      "\n",
      "[Chapter 30: It's Time! It's Time!]{.italic}\n",
      "\n",
      "[]{.calibre11}[]{#The_Master_and_Margarita_split_045.html#filepos1170802\n",
      ".calibre11}\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: Who are the main characters of the book The Master and Margarita?\n",
      "\n",
      "Response: content='The main characters of the book \"The Master and Margarita\" are The Master and Margarita.' response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 859, 'total_tokens': 881}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-871035cc-8ebd-4b00-bcdc-8a37f5f5aa75-0' usage_metadata={'input_tokens': 859, 'output_tokens': 22, 'total_tokens': 881}\n",
      "Sources: ['data\\\\Master and Margarita Bulgakov.md', 'data\\\\Master and Margarita Bulgakov.md', 'data\\\\Master and Margarita Bulgakov.md']\n"
     ]
    }
   ],
   "source": [
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results]) \n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "model = ChatOpenAI()\n",
    "response_text = model.invoke(prompt)\n",
    "\n",
    "sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    "formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d9ae9-fd5d-4e47-b000-dba69943742b",
   "metadata": {},
   "source": [
    "As I mentioned above, the context used to answer the question consists mainly of publishing and copyright information from the text rather than any meaningful content about the plot or characters of the novel.The AI correctly identifies the main characters of The Master and Margarita as \"the Master and Margarita.\" While accurate, the response is somewhat minimal. The novel has many other significant characters, such as Woland, Azazello, Behemoth, and Pontius Pilate. A more complete answer could include these key figures to provide a fuller understanding of the novel's cast. The answer is technically correct but lacks depth.\n",
    "\n",
    "The AI used 881 tokens in total. This suggests that a significant amount of text was processed as part of the context, but the generated answer was relatively short and concise.\n",
    "\n",
    "The finish_reason being 'stop' indicates that the model completed the answer naturally, without being cut off.\n",
    "\n",
    "Let's try more complicated question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50efa362-d4c9-4de3-a6cd-0c7ce49d0366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "Several years passed, and the citizens began to forget Woland, Koroviev\n",
      "and the rest. Many changes took place in the lives of those who suffered\n",
      "from Woland and his company, and however trifling and insignificant\n",
      "those changes are, they still ought to be noted.\n",
      "\n",
      "Georges Bengalsky, for instance, after spending three months in the\n",
      "clinic, recovered and left it, but had to give up his work at the\n",
      "Variety, and that at the hottest time, when the public was flocking\n",
      "after tickets: the memory of black magic and its exposure proved very\n",
      "tenacious. Bengalsky left the Variety, for he understood that to appear\n",
      "every night before two thousand people, to be inevitably recognized and\n",
      "endlessly subjected to jeering questions of how he liked it better, with\n",
      "or without his head, was much too painful.\n",
      "\n",
      "---\n",
      "\n",
      "And, finally, Woland also flew in his true image. Margarita could not\n",
      "have said what his horse's bridle was made of, but thought it might be\n",
      "chains of moonlight, and the horse itself was a mass of darkness, and\n",
      "the horse's mane a storm cloud, and the rider's spurs the white flecks\n",
      "of stars.\n",
      "\n",
      "Thus they flew in silence for a long time, until the place itself began\n",
      "to change below them. The melancholy forests drowned in earthly darkness\n",
      "and drew with them the dim blades of the rivers. Boulders appeared and\n",
      "began to gleam below, with black gaps between them where the moonlight\n",
      "did not penetrate.\n",
      "\n",
      "---\n",
      "\n",
      "Woland raised his sword. Straight away the flesh of the head turned dark\n",
      "and shrivelled, then fell off in pieces, the eyes disappeared, and soon\n",
      "Margarita saw on the platter a yellowish skull with emerald eyes, pearl\n",
      "teeth and a golden foot. The lid opened on a hinge.\n",
      "\n",
      "'Right this second, Messire,' said Koroviev, noticing Woland's\n",
      "questioning look, 'hell appear before you. In this sepulchral silence I\n",
      "can hear the creaking of his patent leather shoes and the clink of the\n",
      "goblet he has just set down on the table, having drunk champagne for the\n",
      "last time in his life. Here he is.'\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: How does Wolands presence affect the characters and events?\n",
      "\n",
      "Response: content=\"Woland's presence causes fear, discomfort, and changes in the lives of the characters. Georges Bengalsky had to give up his work at the Variety due to the memory of black magic and the exposure he experienced. Margarita is in awe of Woland's true image and the transformation of the landscape below them as they fly. Woland's actions, such as raising his sword and transforming a head into a skull, instill a sense of dread and anticipation in the characters. Overall, Woland's presence brings about significant emotional and physical impact on the characters and events in the story.\" response_metadata={'token_usage': {'completion_tokens': 119, 'prompt_tokens': 513, 'total_tokens': 632}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-cc836402-cbdc-44ae-924e-447011ffa034-0' usage_metadata={'input_tokens': 513, 'output_tokens': 119, 'total_tokens': 632}\n",
      "Sources: ['data\\\\Master and Margarita Bulgakov.md', 'data\\\\Master and Margarita Bulgakov.md', 'data\\\\Master and Margarita Bulgakov.md']\n"
     ]
    }
   ],
   "source": [
    "query_text = 'How does Wolands presence affect the characters and events?'\n",
    "results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "model = ChatOpenAI()\n",
    "response_text = model.invoke(prompt)\n",
    "\n",
    "sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    "formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7450dca7-3a61-42f8-b86a-6533fffa7a04",
   "metadata": {},
   "source": [
    "Woland's presence in The Master and Margarita is a catalyst for dramatic changes, fear, and awe. His actions leave lasting impacts on the characters' lives and influence the events of the story in both subtle and overt ways. The retrieved context and AI-generated response effectively illustrate these effects, portraying Woland as a powerful and terrifying force. The AI's response reflects a clear understanding of the material provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d838874d-fd1f-4937-bb97-1f8e07c3f82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "measure. In style and form it is a counterpoint to the rest of the book.\n",
      "Finally, rather late in the process, the master and Margarita appear,\n",
      "with Margarita coming to dominate the second part of the novel. Her\n",
      "story is a romance in the old sense --- the celebration of a beautiful\n",
      "woman, of a true love, and of personal courage.\n",
      "\n",
      "---\n",
      "\n",
      "The first typescript of [The Master]{.italic} and [Margarita,]{.italic}\n",
      "dating to 1938, was dictated to the typist by Bulgakov from this last\n",
      "revision, with many changes along the way. In 1939 he made further\n",
      "alterations in the typescript, the most important of which concerns the\n",
      "fate of the hero and heroine. In the last manuscript version, the fate\n",
      "of the master and Margarita, announced to them by Woland, is to follow\n",
      "Pilate up the path of moonlight to find Yeshua and peace. In the\n",
      "typescript, the fate of the master, announced to Woland by Matthew Levi,\n",
      "speaking for Yeshua, is not to follow Pilate but to go to his 'eternal\n",
      "refuge' with Margarita, in a rather German-Romantic setting, with\n",
      "Schubert's music and blossoming cherry trees. Asked by Woland, 'But why\n",
      "don't you take him with you into the light?' Levi replies in a sorrowful\n",
      "voice, 'He does not deserve the light, he deserves peace.' Bulgakov,\n",
      "still pondering the problem of the master's guilt (and his own, for what\n",
      "\n",
      "---\n",
      "\n",
      "In the evolution of [The Master and Margárita]{.italic}, the Moscow\n",
      "satire of Woland and his retinue versus the literary powers and the\n",
      "imposed normality of Soviet life in general is there from the first, and\n",
      "comes to involve the master when he appears, acquiring details from the\n",
      "writer's own life and with them a more personal tone alongside the\n",
      "bantering irreverence of the demonic retinue. The Pilate story, on the\n",
      "other hand, the story of an act of cowardice and an interrupted\n",
      "dialogue, gains in weight and independence as Bulgakov's work\n",
      "progresses. From a single inset episode, it becomes the centrepiece of\n",
      "the novel, setting off the contemporary events and serving as their\n",
      "measure. In style and form it is a counterpoint to the rest of the book.\n",
      "Finally, rather late in the process, the master and Margarita appear,\n",
      "with Margarita coming to dominate the second part of the novel. Her\n",
      "story is a romance in the old sense --- the celebration of a beautiful\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: What is the relationship between the Master and Margarita, and how does it drive the plot?\n",
      "\n",
      "Response: content='The relationship between the Master and Margarita is a central focus of the novel and drives the plot forward. Margarita dominates the second part of the novel, and her story is described as a romance in the old sense, celebrating a beautiful woman, true love, and personal courage. The fate of the Master and Margarita is intertwined, with different versions of their fate being explored in the manuscript. Ultimately, their relationship and their journey together, whether it be towards finding peace or following Pilate up the path of moonlight, shape the narrative and themes of the novel. Their love story adds depth and emotion to the overall plot of the book.' response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 609, 'total_tokens': 741}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-786a8f89-39b2-4c1e-bac5-ebd83ae26ad6-0' usage_metadata={'input_tokens': 609, 'output_tokens': 132, 'total_tokens': 741}\n",
      "Sources: ['data\\\\Master and Margarita Bulgakov.md', 'data\\\\Master and Margarita Bulgakov.md', 'data\\\\Master and Margarita Bulgakov.md']\n"
     ]
    }
   ],
   "source": [
    "query_text = 'What is the relationship between the Master and Margarita, and how does it drive the plot?'\n",
    "results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "model = ChatOpenAI()\n",
    "response_text = model.invoke(prompt)\n",
    "\n",
    "sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    "formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00ab87f-1f04-4e2a-bc16-5aa3be592c7a",
   "metadata": {},
   "source": [
    "The AI's response is largely based on introductory for the novel, not directly from the narrative itself. But anyway the AI's response succinctly captures these elements based on the retrieved context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "512747fb-00df-4276-8017-f9d94721c9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "several pages the sensation of flight on a broomstick or the gathering\n",
      "of the infamous dead at Satan's annual spring ball, can combine the most\n",
      "acute sense of the fragility of human life with confidence in its\n",
      "indestructibility. Bulgakov underscores the continuity of this verbal\n",
      "world by having certain phrases --- 'Oh, gods, my gods', 'Bring me\n",
      "poison', 'Even by moonlight I have no peace' - migrate from one\n",
      "character to another, or to the narrator. A more conspicuous case is the\n",
      "Pilate story itself, successive parts of which are told by Woland,\n",
      "dreamed by the poet Homeless, written by the master, and read by\n",
      "Margarita, while the whole preserves its stylistic unity. Narrow notions\n",
      "of the 'imitation of reality' break down here. But [The Master and\n",
      "Margarita]{.italic} is true to the broader sense of the novel as a\n",
      "freely developing form embodied in the works of Dostoevsky and Gogol, of\n",
      "Swift and Sterne, of Cervantes, Rabelais and Apuleius. The mobile but\n",
      "\n",
      "---\n",
      "\n",
      "These three stories, in form as well as content, embrace virtually all\n",
      "that was excluded from official Soviet ideology and its literature. But\n",
      "if the confines of 'socialist realism' are utterly exploded, so are the\n",
      "confines of more traditional novelistic realism. [The Master and\n",
      "Margarita]{.italic} as a whole is a consistently free verbal\n",
      "construction which, true to its own premises, can re-create ancient\n",
      "Jerusalem in the smallest physical detail, but can also alter the\n",
      "specifics of the New Testament and play variations on its principal\n",
      "figures, can combine the realities of Moscow life with witchcraft,\n",
      "vampirism, the tearing off and replacing of heads, can describe for\n",
      "several pages the sensation of flight on a broomstick or the gathering\n",
      "of the infamous dead at Satan's annual spring ball, can combine the most\n",
      "acute sense of the fragility of human life with confidence in its\n",
      "indestructibility. Bulgakov underscores the continuity of this verbal\n",
      "\n",
      "---\n",
      "\n",
      "Bulgakov was known well enough, then. But, outside a very small group,\n",
      "the existence of [The Master and Margarita]{.italic} was completely\n",
      "unsuspected. That certainly accounts for some of the amazement caused by\n",
      "its publication. It was thought that virtually all of Bulgakov had found\n",
      "its way into print. And here was not some minor literary remains but a\n",
      "major novel, the author's crowning work. Then there were the qualities\n",
      "of the novel itself --- its formal originality, its devastating satire\n",
      "of Soviet life, and of Soviet literary life in particular, its\n",
      "'theatrical' rendering of the Great Terror of the thirties, the audacity\n",
      "of its portrayal of Jesus Christ and Pontius Pilate, not to mention\n",
      "Satan. But, above all, the novel breathed an air of freedom, artistic\n",
      "and spiritual, which had become rare indeed, not only in Soviet Russia.\n",
      "We sense it in the special tone of Bulgakov's writing, a combination of\n",
      "laughter (satire, caricature, buffoonery) and the most unguarded\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: What literary devices does Bulgakov use in The Master and Margarita to enhance the story?\n",
      "\n",
      "Response: content='Bulgakov uses various literary devices in The Master and Margarita to enhance the story, including the migration of certain phrases from character to character or to the narrator, the use of multiple perspectives to tell the Pilate story, stylistic unity, formal originality, satire, caricature, buffoonery, and a combination of laughter and unguarded freedom in his writing. These devices help to create a unique and richly textured narrative that defies traditional novelistic realism and explores themes of human fragility and indestructibility, freedom, and the boundaries of Soviet ideology and literature.' response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 725, 'total_tokens': 843}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-e007d9de-576e-426b-8d09-948dd71b2251-0' usage_metadata={'input_tokens': 725, 'output_tokens': 118, 'total_tokens': 843}\n",
      "Sources: ['data\\\\Master and Margarita Bulgakov.md', 'data\\\\Master and Margarita Bulgakov.md', 'data\\\\Master and Margarita Bulgakov.md']\n"
     ]
    }
   ],
   "source": [
    "query_text = 'What literary devices does Bulgakov use in The Master and Margarita to enhance the story?'\n",
    "results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "model = ChatOpenAI()\n",
    "response_text = model.invoke(prompt)\n",
    "\n",
    "sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    "formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866748be-5016-405f-acb6-502ba7f69ebd",
   "metadata": {},
   "source": [
    "Actually I am impressed that for a such complicated question the response accurately captures the essence of how Bulgakov employs literary devices to enhance the story. It identifies key devices and explains their impact on the narrative, reflecting the broader themes and stylistic choices described in the context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f253ad3-663a-460e-ae66-df891501fff0",
   "metadata": {},
   "source": [
    "## Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111f3f5-b000-4d1c-9576-b84d2b1a4768",
   "metadata": {},
   "source": [
    "Working on this project was a great experience, and I really enjoyed exploring how an AI can answer questions based on embedded documents. Using \"The Master and Margarita\" as my test text, I was impressed by how well the model handled both simple and more complex questions. It was amazing to see it tackle complicated literary themes and concepts. However, there were some mistakes in the vector contexts, which sometimes led to incomplete or less detailed answers. In the future, I would like to experiment with improving the quality of the context and try different approaches, such as fine-tuning the model or using larger and more varied datasets.\n",
    "\n",
    "One thing that could be improved in the future is adjusting the chunk size and adding overlaps. Some of the context chunks were too large or disconnected, which might have caused the AI to miss important details. By refining the chunk size and overlaps, I believe the AI could better capture the nuances of the text, leading to more accurate and detailed answers.\n",
    "\n",
    "This project showed me the potential of AI in literary analysis, and I’m excited to keep exploring new ways to enhance its accuracy and depth in answering challenging questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
