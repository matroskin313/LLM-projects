{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfbb2e50-9e74-45ac-8b52-354e45397ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "import openai \n",
    "import shutil\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '[my key]'\n",
    "\n",
    "DATA_PATH = 'data/books'\n",
    "CHROMA_PATH = \"chroma\"\n",
    "\n",
    "def load_documents():\n",
    "    loader = DirectoryLoader(DATA_PATH, glob='*.md')\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "documents = load_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1df950-93be-4cc5-83ef-76668e2671d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 documents into 229 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=300,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f'Split {len(documents)} documents into {len(chunks)} chunks.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc557781-8d0c-4d43-b7f0-1cd709834e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were doors all round the hall, but they were all locked; and when\n",
      "Alice had been all the way down one side and up the other, trying every\n",
      "door, she walked sadly down the middle, wondering how she was ever to\n",
      "get out again.\n",
      "\n",
      "Suddenly she came upon a little three-legged table, all made of solid\n",
      "glass; there was nothing on it except a tiny golden key, and Alice’s\n",
      "first thought was that it might belong to one of the doors of the hall;\n",
      "but, alas! either the locks were too large, or the key was too small,\n",
      "but at any rate it would not open any of them. However, on the second\n",
      "time round, she came upon a low curtain she had not noticed before, and\n",
      "behind it was a little door about fifteen inches high: she tried the\n",
      "little golden key in the lock, and to her great delight it fitted!\n",
      "{'source': 'data\\\\books\\\\alice_in_wonderland.md', 'start_index': 6936}\n"
     ]
    }
   ],
   "source": [
    "document = chunks[10]\n",
    "print(document.page_content)\n",
    "print(document.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b82c96-4266-416a-bc51-0dea30277c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new DB from the documents.\n",
    "db = Chroma.from_documents(\n",
    "    chunks, OpenAIEmbeddings(), persist_directory=CHROMA_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e928078d-12f4-4d09-9c8a-c24b7cf1f268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 229 chunks to chroma.\n"
     ]
    }
   ],
   "source": [
    "# Create a new DB from the documents.\n",
    "db = Chroma.from_documents(\n",
    "    chunks, OpenAIEmbeddings(), persist_directory=CHROMA_PATH\n",
    ")\n",
    "#db.persist()\n",
    "print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32695665-fbc5-41ac-b6eb-3b3371787c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "embedding_function = OpenAIEmbeddings()\n",
    "vector = embedding_function.embed_query('apple')\n",
    "print(len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "475381c6-2b62-45b1-bbf1-37ea597f72f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.1354698831743597}\n",
      "{'score': 0.09710853291781452}\n"
     ]
    }
   ],
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "evaluator = load_evaluator('pairwise_embedding_distance')\n",
    "#Run an avaluation\n",
    "x = evaluator.evaluate_string_pairs(prediction='apple', prediction_b='orange')\n",
    "print(x)\n",
    "x1 = evaluator.evaluate_string_pairs(prediction='apple', prediction_b='iphone')\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f52e92b4-da2d-4267-875d-d1043e8e3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = 'How does the first meet of Alice and the Mad Hatter happen?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b99c0b4-7af3-47c7-8ad7-0fa6f5dfa986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DB.\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "812b8711-87be-42b8-a8c3-63b1b54ce3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the DB.\n",
    "results = db.similarity_search_with_relevance_scores(query_text, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b303cdcd-70bf-44bd-a9e4-66832e149e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results) == 0 or results[0][1] < 0.7:\n",
    "    print(f'Unable to find matching results.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3abb50f-e5d4-4114-ab7a-461451a41a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e90d7d8-d519-4fa0-a93c-11bd41621f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "“How dreadfully savage!” exclaimed Alice.\n",
      "\n",
      "“And ever since that,” the Hatter went on in a mournful tone, “he won’t\n",
      "do a thing I ask! It’s always six o’clock now.”\n",
      "\n",
      "A bright idea came into Alice’s head. “Is that the reason so many\n",
      "tea-things are put out here?” she asked.\n",
      "\n",
      "“Yes, that’s it,” said the Hatter with a sigh: “it’s always tea-time,\n",
      "and we’ve no time to wash the things between whiles.”\n",
      "\n",
      "“Then you keep moving round, I suppose?” said Alice.\n",
      "\n",
      "“Exactly so,” said the Hatter: “as the things get used up.”\n",
      "\n",
      "“But what happens when you come to the beginning again?” Alice ventured\n",
      "to ask.\n",
      "\n",
      "“Suppose we change the subject,” the March Hare interrupted, yawning.\n",
      "“I’m getting tired of this. I vote the young lady tells us a story.”\n",
      "\n",
      "“I’m afraid I don’t know one,” said Alice, rather alarmed at the\n",
      "proposal.\n",
      "\n",
      "“Then the Dormouse shall!” they both cried. “Wake up, Dormouse!” And\n",
      "they pinched it on both sides at once.\n",
      "\n",
      "---\n",
      "\n",
      "“How dreadfully savage!” exclaimed Alice.\n",
      "\n",
      "“And ever since that,” the Hatter went on in a mournful tone, “he won’t\n",
      "do a thing I ask! It’s always six o’clock now.”\n",
      "\n",
      "A bright idea came into Alice’s head. “Is that the reason so many\n",
      "tea-things are put out here?” she asked.\n",
      "\n",
      "“Yes, that’s it,” said the Hatter with a sigh: “it’s always tea-time,\n",
      "and we’ve no time to wash the things between whiles.”\n",
      "\n",
      "“Then you keep moving round, I suppose?” said Alice.\n",
      "\n",
      "“Exactly so,” said the Hatter: “as the things get used up.”\n",
      "\n",
      "“But what happens when you come to the beginning again?” Alice ventured\n",
      "to ask.\n",
      "\n",
      "“Suppose we change the subject,” the March Hare interrupted, yawning.\n",
      "“I’m getting tired of this. I vote the young lady tells us a story.”\n",
      "\n",
      "“I’m afraid I don’t know one,” said Alice, rather alarmed at the\n",
      "proposal.\n",
      "\n",
      "“Then the Dormouse shall!” they both cried. “Wake up, Dormouse!” And\n",
      "they pinched it on both sides at once.\n",
      "\n",
      "---\n",
      "\n",
      "“How dreadfully savage!” exclaimed Alice.\n",
      "\n",
      "“And ever since that,” the Hatter went on in a mournful tone, “he won’t\n",
      "do a thing I ask! It’s always six o’clock now.”\n",
      "\n",
      "A bright idea came into Alice’s head. “Is that the reason so many\n",
      "tea-things are put out here?” she asked.\n",
      "\n",
      "“Yes, that’s it,” said the Hatter with a sigh: “it’s always tea-time,\n",
      "and we’ve no time to wash the things between whiles.”\n",
      "\n",
      "“Then you keep moving round, I suppose?” said Alice.\n",
      "\n",
      "“Exactly so,” said the Hatter: “as the things get used up.”\n",
      "\n",
      "“But what happens when you come to the beginning again?” Alice ventured\n",
      "to ask.\n",
      "\n",
      "“Suppose we change the subject,” the March Hare interrupted, yawning.\n",
      "“I’m getting tired of this. I vote the young lady tells us a story.”\n",
      "\n",
      "“I’m afraid I don’t know one,” said Alice, rather alarmed at the\n",
      "proposal.\n",
      "\n",
      "“Then the Dormouse shall!” they both cried. “Wake up, Dormouse!” And\n",
      "they pinched it on both sides at once.\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: How does the first meet of Alice and the Mad Hatter happen?\n",
      "\n",
      "Response: content=\"The first meeting of Alice and the Mad Hatter happens when Alice stumbles upon a tea party where the Mad Hatter, the March Hare, and the Dormouse are in attendance. The Mad Hatter laments that it is always six o'clock and they have no time to wash the tea-things between whiles. Alice asks about the reason for so many tea-things being put out, leading to a conversation that eventually leads to the Mad Hatter suggesting a story be told.\" response_metadata={'token_usage': {'completion_tokens': 99, 'prompt_tokens': 754, 'total_tokens': 853}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-cafde5a6-9020-4c1a-b48c-812cd4b696cf-0' usage_metadata={'input_tokens': 754, 'output_tokens': 99, 'total_tokens': 853}\n",
      "Sources: ['data\\\\books\\\\alice_in_wonderland.md', 'data\\\\books\\\\alice_in_wonderland.md', 'data\\\\books\\\\alice_in_wonderland.md']\n"
     ]
    }
   ],
   "source": [
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "model = ChatOpenAI()\n",
    "response_text = model.invoke(prompt)\n",
    "\n",
    "sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    "formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b192a86-e224-4938-8460-c853732c5464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
